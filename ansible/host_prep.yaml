---
- hosts: convergence_base
  become: true
  become_user: root

  tasks:
  - name: Include variables
    include_vars: vars/default.yaml

  - name: validate proper number of workers (>= 2), if explicit workers are requestd
    fail:
      msg: If workers are requested, a minimum of 2 is required
    when: (ocp_worker_count|int > 0 and ocp_worker_count|int < 2)

  - name: validation for virtual clusters vs baremetal
    block:
    - name: fail if baremetal nodes are requested and AI is not
      # NOTE: Extra baremetal workers (ocp_bm_extra_workers) should be fine with either dev-scripts or AI
      fail:
        msg: baremetal nodes are currently only supported for AI deployments
      when: not ocp_ai|bool and (ocp_bm_masters | default({}) | length > 0 or ocp_bm_workers | default({}) | length > 0)

    - name: fail if virtual and baremetal nodes of the same role are requested
      fail:
        msg: Cannot mix virtual and baremetal nodes of the same role
      when: (ocp_bm_masters | default({}) | length > 0 and ocp_num_masters > 0) or
            (ocp_bm_workers | default({}) | length > 0 and (ocp_num_workers > 0 or ocp_num_extra_workers > 0))

  - name: validation and tweaks for assisted installer
    block:
    - name: fail if RHEL version < 8.3
      fail:
        msg: RHEL 8.3+ is required for the assisted installer deployments
      when: ansible_distribution != "RedHat" or ansible_distribution_version|float < 8.3

    - name: fail if OCP version <= 4.6
      fail:
        msg: "OCP version {{ ocp_version }} is not allowed.  Only OCP greater than 4.6 is currently supported for assisted installer deployments."
      when: ocp_version is version('4.6', 'le', strict=True )
    when: ocp_ai|bool

  - name: OCS validation checks
    when: (enable_ocs | bool)
    block:
    - name: OCS is only allowed for AI
      fail:
        msg: "OCS is only allowed for AI deployments"
      when: not (ocp_ai | bool)

    - name: Number of storage workers must be 3, and must be <= ocp_num_workers
      fail:
        msg: "3 (non-extra) worker (or master/worker combo) nodes are required for OCS"
      when: ocp_num_storage_workers < 3
            or (
                ocp_num_storage_workers > ocp_worker_count|int
                and ocp_num_storage_workers > ocp_master_count|int
               )

  # Temporary (perhaps) until we can figure out how to find a CNV-4.12 repo for RHEL 9
  - name: CNV validation check
    fail:
      msg: Only OCP 4.13+ is supported for RHEL 9 environments, due to CNV repo availability
    when: ocp_version is version('4.12', 'le', strict=True ) and ansible_distribution_version|int == 9

  - name: add RH CA to ca store
    block:
    - name: copy CA cert to anchors dir
      copy:
        src:  "RH-Root-CA.pem"
        dest: "/etc/pki/ca-trust/source/anchors/"
        mode: 0644
    - name: update CAs
      command: update-ca-trust extract

  - name: Disable existing repos
    block:
    - name: get existing repo files
      find:
        paths: /etc/yum.repos.d
        patterns: '*.repo'
      register: repos

    - name: Disable any existing repos
      replace:
        dest: "{{ item.path }}"
        regexp: "enabled=1"
        replace: "enabled=0"
      with_items: "{{ repos.files }}"

  - name: Register host to subscription manager, metal3 dev scripts use subscription manager for RHEL
    block:
    - name: use local rhel-subscription info
      when: secrets_repo is undefined
      block:
      - name: Include rhel-subscription info
        include_vars: vars/rhel-subscription.yaml
      rescue:
      - name: No rhel-subscription info
        pause:
          seconds: 1
          prompt: |
            vars/rhel-subscription.yaml is not present. You can create this
            file manually. The format of the file is:

            rhel_subscription_activation_key: <activation key>
            rhel_subscription_org_id: "xxxxxxx"

            If you do not have the file, we will use your manually provisioned
            subscription
        register: manual_rhel_subscription

    - name: use secrets_repo
      when: secrets_repo is defined
      block:
      - name: set secrets_repo_path from configured secrets_repo
        set_fact:
          secrets_repo_path: "{{ ansible_env.HOME }}/{{ secrets_repo | urlsplit('hostname') }}/{{ (secrets_repo | urlsplit('path') | splitext)[0] }}"
      - name: create base dir for secrets_repo repo
        file:
          path: "{{ secrets_repo_path }}"
          state: directory
          mode: "0755"
      - name: Clone the repo specified in secrets_repo
        git:
          repo: "{{ secrets_repo }}"
          dest: "{{ secrets_repo_path }}"
          version: "{{ secrets_branch | default('HEAD', true) }}"
        environment:
          GIT_SSL_NO_VERIFY: "true"
      - name: Include rhel-subscription info
        include_vars: "{{ secrets_repo_path }}/rhel-subscription.yaml"
      rescue:
      - name: No rhel-subscription info
        pause:
          seconds: 1
          prompt: |
            rhel-subscription.yaml is not present in {{ secrets_repo }}. You must create this
            file. The format of the file is:

            rhel_subscription_activation_key: <activation key>
            rhel_subscription_org_id: "xxxxxxx"

            If you do not have the file, we will use your manually provisioned
            subscription
        register: manual_rhel_subscription

    - name: unregister node
      retries: 3
      delay: 3
      ignore_errors: yes
      redhat_subscription:
        state: absent
        activationkey: "{{ rhel_subscription_activation_key }}"
        org_id: "{{ rhel_subscription_org_id }}"
      when: manual_rhel_subscription is undefined

    - name: Register with activationkey and consume subscriptions matching Red Hat Enterprise Server
      retries: 3
      delay: 3
      redhat_subscription:
        state: present
        force_register: yes
        activationkey: "{{ rhel_subscription_activation_key }}"
        org_id: "{{ rhel_subscription_org_id }}"
        pool: "{{ rhel_subscription_pool|default(omit) }}"
        pool_ids: "{{ rhel_subscription_pool_ids|default(omit) }}"
        server_hostname: "{{ rhel_subscription_server_hostname|default(omit) }}"
      when: manual_rhel_subscription is undefined

    - name: enable required repos
      command: subscription-manager repos --enable={{ ' --enable='.join(rhel_repos[ansible_distribution_version|int]) }}

  - name: install packages and enable services
    block:
    - name: Install packages
      package:
        state: installed
        name: "{{ rhel_packages[ansible_distribution_version|int] | list }}"

    - name: Enable helpful services
      service: name={{ item }} enabled=yes state=started
      with_items:
        - crond
        - libvirtd
        - chronyd
        - tuned
        - firewalld

  - name: configure time on host
    block:
      - name: Set timezone to GMT
        file:
          src: /usr/share/zoneinfo/GMT
          dest: /etc/localtime
          state: link
          force: yes

      - name: Install, Configure and Run Chrony
        include_role:
          name: chrony
        vars:
          chrony_role_action: all
          chrony_ntp_servers:
          - clock.redhat.com
          chrony_ntp_pools:
          - clock.redhat.com

      - name: Ensure chrony has been restarted
        meta: flush_handlers

      - name: Ensure system is NTP time synced
        command: chronyc makestep

      - name: Sync HW clock
        command: hwclock -w

  - name: Check current tuned profile
    command: tuned-adm active
    register: tuned_profile
    changed_when: False

  - name: Set tuned virtualization-host profile
    command: /usr/sbin/tuned-adm profile virtual-host
    when: "'Current active profile: virtual-host' not in tuned_profile.stdout"

  - name: enable nested virt
    lineinfile:
      path: /etc/modprobe.d/kvm.conf
      regexp: '^options kvm-intel nested=.*'
      line: options kvm-intel nested=1
    register: kvm_conf

  - name: reload kvm kernel modules
    when: kvm_conf is changed
    block:
    - name: remove kernel modules
      modprobe:
        name: "{{ item }}"
        state: absent
      with_items:
        - kvm_intel
        - kvm

    - name: load kernel modules
      modprobe:
        name: kvm_intel
        state: present

  - name: Remove home mount point
    mount:
      path: /home
      backup: yes
      state: absent
    register: home_unmounted

  - name: remove lvm device and resize /
    when: home_unmounted is changed
    block:
    - name: get VG name
      shell: >
        echo $(vgs |grep rhel | awk '{print $1}')
      register: vg
    - name: Remove home logical volume
      lvol:
        vg: "{{ vg.stdout }}"
        lv: home
        state: absent
        force: yes
    - name: Extend / logical volume to consume all remaining space in the volume group
      lvol:
        vg: "{{ vg.stdout }}"
        lv: root
        size: +100%FREE
      register: lv_resized
    - name: resize FS on /
      command: /usr/sbin/xfs_growfs /
      when: lv_resized is changed

  - name: Allow 'wheel' group to have passwordless sudo
    lineinfile:
      dest: /etc/sudoers
      state: present
      regexp: '^%wheel'
      line: '%wheel ALL=(ALL) NOPASSWD: ALL'
      validate: 'visudo -cf %s'

  - name: make sure /home is there as the mount plugin with absent removed it earlier
    file:
      path: /home
      state: directory
      mode: '0755'

  - name: Configure NFS server
    import_role:
      name: nfs_server

  - name: masquerade all outgoing traffic
    block:
    - name: Acquire default external interface
      shell: |
        ip r | grep default | head -1 | cut -d ' ' -f 5
      register: ext_intf

    - name: Fail when unable to determine external interface
      fail:
        msg: |
          Unable to determine external interface
      when: ext_intf.stdout == ""

    - name: Make sure all outgoing traffic via ext_intf get masqueraded
      shell: |
        firewall-cmd --direct --permanent --add-rule ipv4 nat POSTROUTING 0 -o "{{ ext_intf.stdout }}" ! -d 172.16.0.0/12 -j MASQUERADE;
        firewall-cmd --reload
